## Daily Schedule Part 2 (Actual &mdash; Kept Retrospectively)

*Regular meeting schedule is Wednesdays and Saturdays, 11:00-12:00*

Back to [Course home page](./index.html)

See also [Daily Schedule - Part 1](./daily_schedule_part1.html)

### Part 2: Data Science Foundations (using Joel Grus, *Data Science from Scratch, 2nd Edition*)

Part 2 Uses Grus and lasts for the remaining three-and-a-half weeks of Term 6

#### Week 4 &mdash; Yet Another Review of Python &mdash; Some Vector and Matrix Algebra &mdash; Statistics and Probability

* June 4 &mdash; Chapters 1-3: Another excellent review of Python and Matplotlib which will help systematize your understanding of the language features you were using in Pasha's book &mdash; The assignment is to do the review of the three chapters, but to completely stop using Jupyter or Jupyter lab, and instead get everything working in PyCharm Professional Edition (free for students) or VS Code (but I have zero experience with that) &mdash; When Grus says (at the beginning of Chapter 2) that you should not be tampering with your base Python environment, he is completely correct (so learn how to make a venv that you could call grus or dsfs and then switch to it &mdash; if you didn't already do that for working through Pasha)
* June 7 &mdash; Chapters 4-6: Linear Algebra (wherein Grus introduces his Vector and Matrix implementations which could have been classes, or could have leveraged numpy, but which he craftily used type aliases, because that was the simplest way to implement from scratch), Statistics, and Probability (due to having taken last fall's Bayesian Statistics class, the math in Chapters 5 and 6 will be review)

#### Week 5 &mdash; Optimization (aka Minimization and Maximization) &mdash; Working with Data

* June 11 &mdash; Chapters 7 and 8: Hypotheses &amp; Inference and Gradient Descent &mdash; Make a local repo from the magic hexijin.github.io GitHub repo, put an index.md file in it, and then push to origin main &mdash; The only remaining step to having your own home page at [hexijin.github.io](https://hexijin.github.io/index.html) is to enable GitHub pages on the magic repo &mdash; In the meantime, you can go straight to [this notes page](https://hexijin.github.io/scientific-data-analysis/hexi/index.html)

#### === BELOW THIS DIVISION IS GOAL/TENTATIVE PLAN &mdash; NOT ACTUAL ===

* June 14 &mdash; Chapters 9 and 10: Getting and Working with Data

#### Week 6 &mdash; Machine Learning &mdash; Neural Networks &mdash; Start Deep Learning

* June 18 &mdash; Chapters 11 and 13: Machine Learning and Naive Bayes
* June 21 &mdash; Chapters 18 and 19: Neural Networks and Deep Learning &mdash; Good prepartion for your coding assessment, would be to do this real-time coding session to see how a real pro codes, including type-hinting, systematic adherence to style choices, and code testing: [Joel Grus - Building a Deep Learning Library](https://joelgrus.com/2017/12/04/livecoding-madness-building-a-deep-learning-library/) (build the code in PyCharm as Grus builds it in VS Code, pausing the video whenever you need to catch up with him) &mdash; This real-time coding session will also give you a blindingly fast overview of Chapters 18 and 19

#### Week 7 &mdash; Continue Deep Learning &mdash; Introduction to Natural Language Processing

* June 25 &mdash; Chapter 21: Natural Language Processing &mdash; Watch the fifth of the 3Blue1Brown videos, [Transformers Explained Visually](https://youtu.be/wjZofJX0v4M), by Grant Sanderson numbered DL1 to DL7 &mdash; "DL" is short for "Deep Learning," and the seven videos were published from 2017 to 2024 &mdash; The fifth video gives you alook into the 2017 transformers revolution, and at what you would study next if you want to keep getting closer to the state of the art of machine learning and LLMs

See also [Looking Beyond](./looking_beyond.html)
